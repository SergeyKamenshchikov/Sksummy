{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### LIbraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T16:18:10.446207Z",
     "start_time": "2021-01-20T16:17:34.422194Z"
    },
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\skamenshchikov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "import time, winsound, random\n",
    "from random import randint\n",
    "# general\n",
    "\n",
    "# process arrays and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import fuzzy_pandas as fpd\n",
    "from collections import Counter\n",
    "#/process arrays and dataframes\n",
    "\n",
    "# parallel calculations\n",
    "from tqdm import tqdm\n",
    "#/parallel calculations\n",
    "\n",
    "# web parsing\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import chromedriver_binary\n",
    "from requests import get\n",
    "#/web parsing\n",
    "\n",
    "# parsing libs\n",
    "import arxiv\n",
    "import wikipediaapi\n",
    "from googlesearch import search  \n",
    "#/parsing libs\n",
    "\n",
    "# read .pdf\n",
    "from tika import parser\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "#/read .pdf\n",
    "\n",
    "# text processing\n",
    "import spacy,nltk,string,re\n",
    "import neuralcoref\n",
    "import networkx as nx\n",
    "from spacy.symbols import nsubj, nsubjpass, VERB\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from more_itertools import unique_everseen\n",
    "from textblob import TextBlob\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.max_length = 50000000\n",
    "#/text processing\n",
    "\n",
    "# create .docx\n",
    "import docx\n",
    "from docx import Document\n",
    "from docx.shared import Cm\n",
    "from docx.shared import Pt\n",
    "from docx.enum.dml import MSO_THEME_COLOR_INDEX\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.shared import Pt\n",
    "#/create .docx\n",
    "\n",
    "# keywords extraction\n",
    "import yake\n",
    "#/keywords extraction\n",
    "\n",
    "# extractive summarizer\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "#/extractive summarizer\n",
    "\n",
    "# abstractive summarizer\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import textstat\n",
    "import torch\n",
    "#/abstractive summarizer\n",
    "\n",
    "# many-to-many evaluation\n",
    "from rouge import Rouge\n",
    "from rouge_score import rouge_scorer\n",
    "#/many-to-many evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T16:22:11.233726Z",
     "start_time": "2021-01-20T16:22:11.227743Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "UPLOAD_FOLDER = 'docs/'\n",
    "\n",
    "threshold = 0.8 #extension boundary\n",
    "page_number = 10 # page volume\n",
    "max_length = 60 #number of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "### Feature toggles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T16:22:14.487997Z",
     "start_time": "2021-01-20T16:22:14.481019Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "filter_request = False\n",
    "paraphrase = False\n",
    "compress = True\n",
    "\n",
    "wiki_sum = True\n",
    "gogle_sum = True\n",
    "arxiv_sum = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### CDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T16:23:02.894278Z",
     "start_time": "2021-01-20T16:23:02.537341Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "##### HTML parsing #####\n",
    "def parse_google_page(url): \n",
    "    try:\n",
    "        title = BeautifulSoup(get(url).content, 'html.parser').title.getText()\n",
    "        parser = HtmlParser.from_url(url, Tokenizer(\"English\"))\n",
    "        \n",
    "        summarizer = Summarizer(Stemmer(\"English\"))\n",
    "        summarizer.stop_words = get_stop_words(\"English\")\n",
    "\n",
    "        sentences = []\n",
    "        for i in summarizer(parser.document, 1000000):\n",
    "            sentences.append(str(i))\n",
    "        txt = ' '.join(sentences)\n",
    "    except:\n",
    "        txt = ''\n",
    "        title = ''\n",
    "    \n",
    "    return txt, title\n",
    "\n",
    "def striphtml(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', data)\n",
    "\n",
    "def get_unique_text(document):\n",
    "    unique_sentences = []\n",
    "    for sentence in [sent.raw for sent in TextBlob(document).sentences]:\n",
    "        if sentence not in unique_sentences:\n",
    "            unique_sentences.append(sentence)\n",
    "    return ' '.join(unique_sentences)\n",
    "\n",
    "def get_text(url):\n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page)\n",
    "    fetched_text = ' '.join(map(lambda p:p.text,soup.find_all('p')))\n",
    "    return fetched_text\n",
    "#####/HTML parsing #####\n",
    "\n",
    "############# Parse Wiki ############# \n",
    "def parse_wiki(google_url):\n",
    "    \n",
    "    # load driver\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    #/load driver\n",
    "    \n",
    "    # get urls  \n",
    "    driver.get(google_url)\n",
    "    time.sleep(randint(1,5))\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source,'lxml')\n",
    "    result_div = soup.find_all('div', attrs={'class': 'g'})\n",
    "\n",
    "    links = []\n",
    "    titles = []\n",
    "    errors = []\n",
    "\n",
    "    descriptions = []\n",
    "    for r in result_div:\n",
    "        try:\n",
    "            link = r.find('a', href=True)\n",
    "            title = None\n",
    "            title = r.find('h3')\n",
    "\n",
    "            if isinstance(title,Tag):\n",
    "                title = title.get_text()\n",
    "\n",
    "            description = None\n",
    "            description = r.find('span', attrs={'class': 'st'})\n",
    "\n",
    "            if isinstance(description, Tag):\n",
    "                description = description.get_text()\n",
    "\n",
    "            if link != '' and title != '' and description != '':\n",
    "                links.append(link['href'])\n",
    "                titles.append(title)\n",
    "                descriptions.append(description)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    url_list = links[:(page_number)]\n",
    "    url_list = [i for i in url_list if 'https://en.wikipedia.org' in i]\n",
    "    \n",
    "    title_list = []\n",
    "    for i in url_list:\n",
    "        try:\n",
    "            if 'https://en.wikipedia.org' in i: \n",
    "                title_list.append(i.split('/')[4])  \n",
    "        except:\n",
    "            continue\n",
    "    #/ get urls\n",
    "        \n",
    "    driver.stop_client()\n",
    "    driver.close()\n",
    "    \n",
    "    return title_list     \n",
    "############# Parse Wiki ##############\n",
    "\n",
    "############# Parse Arxiv #############\n",
    "def parse_arxiv(query):\n",
    "    \n",
    "    arxivtext = ''  \n",
    "    \n",
    "    urls = []\n",
    "    titles = []\n",
    "  \n",
    "    arxiv_data = arxiv.query(query=query, max_results=page_number)\n",
    "\n",
    "    urls = [i['id'].replace('arxiv.org/', 'export.arxiv.org/') for i in arxiv_data]\n",
    "    titles = [i['title'] for i in arxiv_data]\n",
    "    abstracts = [i['summary'] for i in arxiv_data] \n",
    "\n",
    "    txts = []\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install()) \n",
    "\n",
    "    for i in tqdm(urls):\n",
    "    \n",
    "        driver.get(i)\n",
    "        soup = BeautifulSoup(driver.page_source,'lxml')\n",
    "        result_div = soup.find_all('blockquote', attrs={'class': 'abstract mathjax'})[0]\n",
    "        abstract = result_div.get_text().replace('\\n',' ').replace('\\t',' ').strip()\n",
    "\n",
    "        file_data = parser.from_file(i.replace('abs', 'pdf'))['content']\n",
    "        content = file_data.replace('\\n',' ').replace('\\t',' ').strip()\n",
    "\n",
    "        extended_abstract = filter_text(content, abstract, threshold=0.01).replace('\\n',' ').replace('\\t',' ').strip()\n",
    "        txts.append(extended_abstract)\n",
    "    \n",
    "    driver.stop_client()\n",
    "    driver.close()\n",
    "\n",
    "    arxivtext = re.sub('[^A-Za-z0-9.]+', ' ', '; '.join(txts))\n",
    "\n",
    "    df = pd.DataFrame(list(zip(txts, urls, titles)), columns=['text','link', 'page'])\n",
    "    \n",
    "    return arxivtext, titles, df\n",
    "#############/Parse Arxiv #############\n",
    "\n",
    "############# Parse Google ###############\n",
    "def parse_google(query):   \n",
    "    \n",
    "    txt = []\n",
    "    titles = []\n",
    "    errors = []\n",
    "\n",
    "    # load driver\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    #/load driver \n",
    "\n",
    "    # get urls\n",
    "    google_url = \"https://www.google.com/search?q=\" + query + \"&num=\" + str(page_number+1)\n",
    "    \n",
    "    if filter_request == True:\n",
    "        google_url = google_url + '&searchtype=all&source=header&start=0&date-filter_by=past_' + str(months_delta)\n",
    "        google_url = google_url + '&hl=en&gl=en' + '&lr=lang_en&cr=countryGB'\n",
    "    \n",
    "    driver.get(google_url)\n",
    "    time.sleep(randint(1,5))\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source,'lxml')\n",
    "    result_div = soup.find_all('div', attrs={'class': 'g'})\n",
    "\n",
    "    links = []\n",
    "    titles = []\n",
    "    errors = []\n",
    "\n",
    "    descriptions = []\n",
    "    for r in result_div:\n",
    "        try:\n",
    "            link = r.find('a', href=True)\n",
    "            title = None\n",
    "            title = r.find('h3')\n",
    "\n",
    "            if isinstance(title,Tag):\n",
    "                title = title.get_text()\n",
    "\n",
    "            description = None\n",
    "            description = r.find('span', attrs={'class': 'st'})\n",
    "\n",
    "            if isinstance(description, Tag):\n",
    "                description = description.get_text()\n",
    "                \n",
    "            wikiarxiv_filter = ('wikipedia.org' not in link['href']) and ('arxiv.org' not in link['href'])\n",
    "            patent_filter = ('patents.google.com/' not in link['href'])\n",
    "\n",
    "            if wikiarxiv_filter and patent_filter and link != '' and title != '' and description != '':\n",
    "                links.append(link['href'])\n",
    "                titles.append(title)\n",
    "                descriptions.append(description)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    url_list = list(set(links))[:(page_number)] \n",
    "    #/ get urls\n",
    "    \n",
    "    for j in tqdm(url_list):\n",
    "        delta = random.randint(1,8)\n",
    "        time.sleep(delta) \n",
    "        \n",
    "        try:  \n",
    "            if str(j).endswith('.pdf'):\n",
    "                file_data = parser.from_file(str(j))        \n",
    "                t = file_data['content'].replace('\\n','')    \n",
    "                titles.append(t[:100])\n",
    "            else:\n",
    "                t = parse_google_page(j)[0].replace('\\n','') \n",
    "                titles.append(parse_google_page(j)[1].replace('\\n',''))\n",
    "            \n",
    "            txt.append(t)\n",
    "            \n",
    "        except:\n",
    "            print('Parsing error:',str(j))\n",
    "            errors.append(str(j))\n",
    "          \n",
    "    df = pd.DataFrame(list(zip(txt, url_list, titles)), columns=['text','link', 'page'])\n",
    "    df = df[~df['page'].str.contains('|'.join(['403','404']))]\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    googletext = re.sub('[^A-Za-z0-9.]+', ' ', '; '.join(list(df['text'])))\n",
    "    titles = list(df['page'])\n",
    "   \n",
    "    return googletext, errors, df, titles\n",
    "#############/Parse Google ###############\n",
    "\n",
    "############## Text processing #########\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)\n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "def text_normalize(txt):\n",
    "    processed_text = re.sub('[^a-zA-Z]', ' ', txt)\n",
    "    processed_text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",processed_text)\n",
    "    processed_text=re.sub(\"(\\\\d|\\\\W)+\",\" \",processed_text)\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(processed_text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if not word in stop_words]\n",
    "    tokens = [i for i in tokens if (tags(i) in ['NN', 'NNP', 'NNS', 'NNPS'])]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def filter_triplet(final_text):\n",
    "    \n",
    "    final_text = get_unique_text(final_text)\n",
    "    doc = nlp(final_text)\n",
    "    valid_sents = []\n",
    "\n",
    "    for s in list(doc.sents):\n",
    "        if syntax_full(s):\n",
    "            valid_sents.append(s.text)\n",
    "    \n",
    "    final_text = ' '.join(valid_sents)\n",
    "    \n",
    "    return final_text\n",
    "\n",
    "def coref_res(rawtext, coref_greedn = 0.5):\n",
    "\n",
    "    neuralcoref.add_to_pipe(nlp, greedyness = coref_greedn, store_scores=False)\n",
    "    doc = nlp(rawtext)\n",
    "\n",
    "    resolved = list(tok.text_with_ws for tok in doc)\n",
    "\n",
    "    for cluster in doc._.coref_clusters:\n",
    "        for coref in cluster:\n",
    "            if coref != cluster.main:\n",
    "                if coref.text[0].isalpha() and coref.text[0].isupper():\n",
    "\n",
    "                    main_words_list=word_tokenize(cluster.main.text)\n",
    "                    main_words_list[0]=main_words_list[0].capitalize()\n",
    "                    resolved[coref.start] = detokenizer(main_words_list) + doc[coref.end-1].whitespace_\n",
    "\n",
    "                for i in range(coref.start+1, coref.end):\n",
    "                    resolved[i] = \"\"\n",
    "            else:\n",
    "                resolved[coref.start] = cluster.main.text + doc[coref.end-1].whitespace_\n",
    "                for i in range(coref.start+1, coref.end):\n",
    "                    resolved[i] = \"\"\n",
    "\n",
    "    text_resolved = ''.join(resolved)\n",
    "    nlp.remove_pipe(\"neuralcoref\")\n",
    "\n",
    "    return text_resolved\n",
    "\n",
    "def compress(spacy_sents,sents_whitelist):\n",
    "    blacklist_tokens=[]\n",
    "    n=1\n",
    "    for sent in spacy_sents:\n",
    "        if (n in sents_whitelist):\n",
    "            for token in sent:\n",
    "                if token.dep_ in ['appos','advmod']:\n",
    "                    token_sub_tree=token.subtree\n",
    "                    for t in token_sub_tree:\n",
    "                        blacklist_tokens.append(t.i)\n",
    "\n",
    "        n=n+1\n",
    "    return(blacklist_tokens)\n",
    "\n",
    "def spacy_compress(rawtext):\n",
    "\n",
    "    doc1 = nlp(rawtext)\n",
    "    sents_whitelist = get_sents_ids_whitelist(doc1.sents)\n",
    "\n",
    "    tokens_blacklist = compress(doc1.sents,sents_whitelist)\n",
    "    sents_tokens = get_list_sents_tokens(doc1.sents,sents_whitelist,tokens_blacklist)\n",
    "    compressed_text_sents = []\n",
    "\n",
    "    for s in sents_tokens:\n",
    "        text=detokenizer(s)\n",
    "        compressed_text_sents.append(text)\n",
    "    compressed_text_sents=sentence_grammar_fix(compressed_text_sents)\n",
    "    text =' '.join(compressed_text_sents)\n",
    "\n",
    "    return(text)\n",
    "##### Text processing #####\n",
    "\n",
    "############## Get summary #############\n",
    "def get_summary(rawtext, sentences):\n",
    "    \n",
    "    stemmer = Stemmer(\"english\")\n",
    "    summarizer = Summarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words(\"english\")\n",
    "    parser = PlaintextParser.from_string(' '.join(sent_tokenize(rawtext)[6:]), Tokenizer(\"english\"))\n",
    "\n",
    "    text_list = []\n",
    "    for sentence in summarizer(parser.document, sentences):\n",
    "        text_list.append(str(sentence))\n",
    "\n",
    "    txt = ' '.join(sent_tokenize(rawtext)[:6]) + ' '+' '.join(text_list)\n",
    "\n",
    "    z = 0\n",
    "    output = []\n",
    "    \n",
    "    for i in nltk.sent_tokenize(txt):\n",
    "        output.append(str(i) + '==')\n",
    "    \n",
    "    txt = ''.join(output)\n",
    "    \n",
    "    return txt\n",
    "##############/Get summary #############\n",
    "\n",
    "############## Get tags and entities ###########\n",
    "def graph_keys(final_text, top_number):\n",
    "    \n",
    "    bigrams = list(nltk.ngrams(text_normalize(final_text.lower()),2))\n",
    "    bigrams = [' '.join(i) for i in bigrams if (i[0]!=i[1])] \n",
    "    bigram_counts = collections.Counter(bigrams)\n",
    "    \n",
    "    df = pd.DataFrame(bigram_counts.most_common(len(bigram_counts)), columns=['bigram', 'count'])[:top_number]\n",
    "    df['count'] = 100*df['count']/df['count'].sum().astype(int) \n",
    "    keys = ', '.join(list(df['bigram'].astype(str)))\n",
    "\n",
    "    return keys\n",
    "\n",
    "def yake_keys(text, keys_number):\n",
    "    сustom_kw_extractor = yake.KeywordExtractor(lan=\"en\", n=2, top=keys_number)\n",
    "    keywords = сustom_kw_extractor.extract_keywords(text)\n",
    "    keywords = ', '.join([i[1] for i in keywords])\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def get_entities(rawtext, tops):\n",
    "    spacy_nlp = spacy.load('en_core_web_lg', disable=[\"tagger\",\"parser\"])\n",
    "    nlp.max_length = 1000000000000\n",
    "    doc = spacy_nlp(rawtext)\n",
    "\n",
    "    ners = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['ORG', 'PERSON']:\n",
    "            ners.append(ent.text)\n",
    "   \n",
    "    ner_counts = collections.Counter(ners)\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame(ner_counts.most_common(len(ner_counts)), columns=['ner_names', 'count'])[:tops]\n",
    "        df['count'] = 100*df['count']/df['count'].sum().astype(int) \n",
    "        keys = ', '.join(list(df['ner_names'].astype(str)))\n",
    "    except:\n",
    "        keys = ''\n",
    "    \n",
    "    return keys\n",
    "############## Get tags and entities #############\n",
    "\n",
    "############## Add keyurls ################\n",
    "def add_keyurls(final_keys, query):\n",
    "    url_keys = []\n",
    "    for i in final_keys.split(','):\n",
    "        url = 'https://www.google.com/search?q=' + '+'.join(re.sub(r\" ?\\([^)]+\\)\", \"\", i).strip().split()) + '+' + query + '/keyword/' + i \n",
    "        url_keys.append(url)\n",
    "        \n",
    "    return url_keys     \n",
    "##############/Add urls ###################\n",
    "\n",
    "##### Abstractive summarization #############\n",
    "def get_response(input_text,num_return_sequences):\n",
    "    \n",
    "    batch = tokenizer.prepare_seq2seq_batch([input_text], truncation=True, padding='longest', max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch, max_length=60, num_beams=10, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    \n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    \n",
    "    return tgt_text\n",
    "#####/Abstractive summarization #############\n",
    "\n",
    "############# Doc preparation ##########\n",
    "def add_hyperlink(paragraph, text, url, flag):\n",
    "    part = paragraph.part\n",
    "    r_id = part.relate_to(url, docx.opc.constants.RELATIONSHIP_TYPE.HYPERLINK, is_external=True)\n",
    "\n",
    "    # Create the w:hyperlink tag and add needed values\n",
    "    hyperlink = docx.oxml.shared.OxmlElement('w:hyperlink')\n",
    "    hyperlink.set(docx.oxml.shared.qn('r:id'), r_id, )\n",
    "\n",
    "    # Create a w:r element and a new w:rPr element\n",
    "    new_run = docx.oxml.shared.OxmlElement('w:r')\n",
    "    rPr = docx.oxml.shared.OxmlElement('w:rPr')\n",
    "\n",
    "    # Join all the xml elements together add add the required text to the w:r element\n",
    "    new_run.append(rPr)\n",
    "    new_run.text = text\n",
    "    hyperlink.append(new_run)\n",
    "\n",
    "    # Create a new Run object and add the hyperlink into it\n",
    "    r = paragraph.add_run()\n",
    "    r._r.append (hyperlink) \n",
    "\n",
    "    # A workaround for the lack of a hyperlink style (doesn't go purple after using the link)\n",
    "    # Delete this if using a template that has the hyperlink style in it\n",
    "    r.font.color.theme_color = MSO_THEME_COLOR_INDEX.HYPERLINK\n",
    "    r.font.underline = flag\n",
    "\n",
    "    return hyperlink\n",
    "\n",
    "def save_doc(final_summary, summary, query, score, compression):\n",
    "    \n",
    "    sent_list = list(final_summary.split(sep='<hr>'))\n",
    "    doc = Document()\n",
    "    style = doc.styles['Normal']\n",
    "    \n",
    "    font = style.font\n",
    "    font.name = 'Times New Roman'\n",
    "    font.size = Pt(12)\n",
    "\n",
    "    hd = doc.add_paragraph()\n",
    "    hd.alignment = WD_ALIGN_PARAGRAPH.LEFT\n",
    "    hd.add_run('Summary').bold = True\n",
    "\n",
    "    if query != 'none':\n",
    "        hd = doc.add_paragraph('Request: ' + \"''\" + query + \"''\")\n",
    "\n",
    "    hd = doc.add_paragraph('Information: ' + str(score))\n",
    "    hd = doc.add_paragraph('Word compression: ' + str(compression))\n",
    "    hd = doc.add_paragraph('Model efficiency: ' + str(round((score/compression),2)))  \n",
    "    \n",
    "    r = hd.add_run()\n",
    "    for i in sent_list:\n",
    "        hd.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY\n",
    "\n",
    "        if query != 'none':\n",
    "            try:\n",
    "                link = re.search(r\"<a href=(.*?)target='_blank'\", str(i)).group(1).replace(' ','')\n",
    "                hd = doc.add_paragraph(striphtml(str(i)).replace('<hr>','').replace('<u>','').replace('More',''))               \n",
    "                add_hyperlink(hd, 'More', link, True).add_run()\n",
    "            except:\n",
    "                link = ''\n",
    "        if query == 'none':\n",
    "            hd = doc.add_paragraph(striphtml(str(i)).replace('<hr>','').replace('<u>','').replace('More',''))    \n",
    "         \n",
    "    doc.save('docs/' + summary + '.docx')\n",
    "    \n",
    "    return True\n",
    "#############/Doc preparation ##########\n",
    "\n",
    "############## Sandbox functions ##########\n",
    "def longest_common_substring(s1, s2):\n",
    "  m = [[0] * (1 + len(s2)) for i in range(1 + len(s1))]\n",
    "  longest, x_longest = 0, 0\n",
    "  for x in range(1, 1 + len(s1)):\n",
    "    for y in range(1, 1 + len(s2)):\n",
    "      if s1[x - 1] == s2[y - 1]:\n",
    "        m[x][y] = m[x - 1][y - 1] + 1\n",
    "        if m[x][y] > longest:\n",
    "          longest = m[x][y]\n",
    "          x_longest = x\n",
    "      else:\n",
    "        m[x][y] = 0\n",
    "  return s1[x_longest - longest: x_longest]\n",
    "\n",
    "def longest_common_sentence(s1, s2):\n",
    "    s1_words = s1.split(' ')\n",
    "    s2_words = s2.split(' ')\n",
    "    return ' '.join(longest_common_substring(s1_words, s2_words))\n",
    "\n",
    "def css(a,b):\n",
    "    if len(a.split()) > 0:\n",
    "        score = len(longest_common_sentence(a,b).split())/len(a.split())\n",
    "    else:    \n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def readingTime(mytext):\n",
    "    total_words = len(word_tokenize(mytext))\n",
    "    estimatedTime = round(total_words/200.0,1)\n",
    "    return estimatedTime\n",
    "\n",
    "def grey_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "    return \"hsl(0, 0%%, %d%%)\" % random.randint(60, 100)\n",
    "\n",
    "def tags(x):\n",
    "    return nltk.pos_tag(nltk.word_tokenize(x))[0][1]\n",
    "\n",
    "def syntax_full(spacy_sentence):\n",
    "    result=[]\n",
    "    for token in spacy_sentence:\n",
    "        if (token.dep == nsubj or token.dep == nsubjpass) and token.head.pos == VERB:\n",
    "            result.append(token.head)\n",
    "    if result:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_min_num_of_clauses(spacy_sentence, n):\n",
    "    result=[]\n",
    "    for token in spacy_sentence:\n",
    "        if (token.dep_ in ['nsubj','nsubjpass','csubj','expl']) and (token.head.pos_ == 'VERB' or token.head.pos_ == 'AUX'):\n",
    "            result.append(token.head.text)\n",
    "    if len(result)>=n:\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_sents_ids_whitelist(spacy_sents):\n",
    "    whitelist=[]\n",
    "    i=1\n",
    "    sents_texts=[]\n",
    "    for sent in spacy_sents:\n",
    "        if (sent.text not in sents_texts) and check_min_num_of_clauses(sent,1):\n",
    "            whitelist.append(i)\n",
    "            sents_texts.append(sent.text)\n",
    "        i=i+1\n",
    "    return(whitelist)\n",
    "\n",
    "def get_list_sents_tokens(spacy_sents,sents_whitelist,blacklist_tokens):\n",
    "    sents_tokens=[]\n",
    "    n=1\n",
    "    for sent in spacy_sents:\n",
    "        sent_tokens=[]\n",
    "        if (n in sents_whitelist):\n",
    "            for token in sent:\n",
    "                if (token.i not in blacklist_tokens):\n",
    "                    sent_tokens.append(token.text)\n",
    "            sents_tokens.append(sent_tokens)\n",
    "            sent_tokens=[]\n",
    "\n",
    "        n=n+1\n",
    "    return(sents_tokens)\n",
    "\n",
    "def detokenizer(list_of_tokens):\n",
    "    text_str=\"\".join([\" \"+w if not w.startswith(\"'\") and not w.startswith(\"’\") and w!='' and w not in string.punctuation else w for w in list_of_tokens]).strip()\n",
    "    return(text_str)\n",
    "\n",
    "def sentence_grammar_fix(sentences):\n",
    "    fixed=[]\n",
    "    for sent in sentences:\n",
    "\n",
    "        sent=sent.strip()\n",
    "        sent=sent.replace('\\n','')\n",
    "        sent=sent.replace('()','')\n",
    "\n",
    "        sent=re.sub('\\s+',' ',sent)\n",
    "        sent=sent+'.'\n",
    "        sent=re.sub(r'([,.\\-—:])+',r'\\1',sent)\n",
    "\n",
    "        if len(sent)>1:\n",
    "            if sent[0] in ['.',',','-','—']:\n",
    "                sent=sent[1:]\n",
    "        sent=sent.strip()\n",
    "\n",
    "        if len(sent)>1:\n",
    "            if sent[0].isalpha():\n",
    "                sent=sent[0].upper()+sent[1:]\n",
    "        fixed.append(sent)\n",
    "\n",
    "    return(fixed)\n",
    "\n",
    "def get_scores(report_summary, final_text):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(' '.join(text_normalize(report_summary)).lower(), ' '.join(text_normalize(final_text)).lower())\n",
    "    scores = round(list(list(scores.values())[0])[2],2)\n",
    "    \n",
    "    return scores \n",
    "##############/Sandbox functions ##########\n",
    "\n",
    "############## Extend abstract ##########\n",
    "def get_ngrams(text): \n",
    "    grams = nltk.ngrams(text.split(), 2)\n",
    "    grams_list = []\n",
    "    for i in grams:\n",
    "        grams_list.append(i)\n",
    "    \n",
    "    return grams_list \n",
    "\n",
    "def get_jaccard_sim(a,b):\n",
    "    a, b = set(get_ngrams(a)), set(get_ngrams(b)) \n",
    "    c = a.intersection(b)\n",
    "\n",
    "    return round(float(len(c)/len(a)), 2)\n",
    "\n",
    "def filter_text(content, abstract, threshold=0.5, content_type='arxiv'): \n",
    "    \n",
    "    content_list = []   \n",
    "    \n",
    "    for j in content.split('.'):\n",
    "        try:\n",
    "            sim_score = get_jaccard_sim(j, abstract)\n",
    "        except:\n",
    "            sim_score = 0\n",
    "            \n",
    "        if sim_score > threshold:\n",
    "            content_list.append(j)    \n",
    "        \n",
    "        if content_type == 'wiki':\n",
    "            reduced_list = [i for i in content_list if i not in list(abstract.split('.'))]\n",
    "            final_list = list(dict.fromkeys(abstract.split('.') + reduced_list)) \n",
    "        else:\n",
    "            final_list = content_list \n",
    "                        \n",
    "    return '. '.join(final_list)\n",
    "##############/Extend abstract #########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T16:22:31.957342Z",
     "start_time": "2021-01-20T16:22:30.095243Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window smart glass\n"
     ]
    }
   ],
   "source": [
    "query = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse web sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse Wiki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T16:23:21.387714Z",
     "start_time": "2021-01-20T16:23:08.381017Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [C:\\Users\\skamenshchikov\\.wdm\\drivers\\chromedriver\\win32\\87.0.4280.88\\chromedriver.exe] found in cache\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heated_glass\n",
      "\n",
      "Heated glass is a resistance heater created when a transparent, electrically conductive coating is applied to float glass and then subjected to an electric current.  The electric current in the coating creates heat energy, which warms the glass until the glass radiates heat. ...\n",
      "\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wikitext = ''\n",
    "wikikeys = ''\n",
    "\n",
    "df_wiki = pd.DataFrame()\n",
    "\n",
    "if wiki_sum == True: \n",
    "    \n",
    "    wiki_wiki = wikipediaapi.Wikipedia('en', extract_format=wikipediaapi.ExtractFormat.WIKI)\n",
    "    \n",
    "    red_query = \"https://www.google.com/search?q=\" + 'site:https://en.wikipedia.org ' + query + \"&num=\" + str(page_number+1)\n",
    "    red_query = red_query + '&searchtype=all&source=header'\n",
    "    \n",
    "    wiki_titles = parse_wiki(red_query)\n",
    "\n",
    "    txts = []\n",
    "    titles = []\n",
    "\n",
    "    for i in tqdm(wiki_titles): \n",
    "        \n",
    "        page_sum = wiki_wiki.page(i).summary\n",
    "        page_txt = wiki_wiki.page(i).text\n",
    "        sent_list = filter_text(page_txt, page_sum, threshold=threshold, content_type='wiki')\n",
    "       \n",
    "        titles.append(i)\n",
    "        txts.append(''.join(sent_list).replace('\\n', ''))        \n",
    "    \n",
    "    wikitext = ''.join(txts).replace('\\n','') \n",
    "\n",
    "    if compress == True:\n",
    "        wikitext = coref_res(filter_triplet(wikitext))\n",
    "\n",
    "    url_list = [str('https://en.wikipedia.org/wiki/' + i)  for i in wiki_titles] \n",
    "    \n",
    "    df_wiki = pd.DataFrame(list(zip(txts, url_list, titles)), columns=['text','link', 'page'])\n",
    "    df_wiki.replace('', np.nan, inplace=True)\n",
    "    df_wiki.dropna(inplace=True)\n",
    "    \n",
    "    random_num = randint(1,len(df_wiki))  \n",
    "    \n",
    "    print(df_wiki['page'][random_num-1]+'\\n')\n",
    "    print(df_wiki['text'][random_num-1][:1000]+'...'+'\\n')\n",
    "\n",
    "winsound.Beep(2500, 1000)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiki output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T16:23:49.016565Z",
     "start_time": "2021-01-20T16:23:49.000607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Smart glass or switchable glass (also smart windows or switchable windows in those applications) is a glass or glazing whose light transmission properties are altered when voltage, light, or heat is applied.  In general, the glass changes from transparent to translucent and vice versa, changing from letting light pass through to blocking some (or all) wavelengths of light and vice versa. Smart glass technologies include electrochromic, photochromic, thermochromic, suspended-particle, micro-blind, and polymer-dispersed liquid-crystal devices. When installed in the envelope of buildings, smart glass creates climate adaptive building shells. Smart film, also called Switchable film, is a product that is capable of adjusting light transmission between transparent and opaque using AC power.  Due to moisture sensitivity, earlier versions of the film were used only to make smart glass by lamination on glass.  With continual improvement in moisture resistance, the new (3rd) generation of the film can be directly installed on existing windows with special glue or self-adhesive.  It combines many functions, such as light adjustment, UV and infrared blocking, advertising and security. Most of the film applications are via glass, acrylic or polycarbonate laminates, mainly having to do with the voltage (110VAC) required to operate the film.  Companies continue to attempt various installation methods in order to use the film by itself without having to add the lamination cost. One of the advantages of smart film is that it eliminates the need for blinds, shades or window treatments. An electrochromic device (ECD) controls optical properties such as optical transmission, absorption, reflectance and/or emittance in a continual but reversible manner on application of voltage (electrochromism).  This property enables an ECD to be used for applications like smart glass, electrochromic mirrors, and electrochromic display devices. Electrochromism is the phenomenon where the color or opac...'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitext[:2000] + '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse Arxiv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T16:24:51.514476Z",
     "start_time": "2021-01-20T16:23:53.363483Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [C:\\Users\\skamenshchikov\\.wdm\\drivers\\chromedriver\\win32\\87.0.4280.88\\chromedriver.exe] found in cache\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]2021-01-20 19:24:00,102 [MainThread  ] [INFO ]  Retrieving http://export.arxiv.org/pdf/1911.05273v1 to C:\\Users\\SKAMEN~1\\AppData\\Local\\Temp/pdf-1911.05273v1.\n",
      " 10%|████████▎                                                                          | 1/10 [00:08<01:16,  8.52s/it]2021-01-20 19:24:04,595 [MainThread  ] [INFO ]  Retrieving http://export.arxiv.org/pdf/1911.02990v2 to C:\\Users\\SKAMEN~1\\AppData\\Local\\Temp/pdf-1911.02990v2.\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:14<01:01,  7.68s/it]2021-01-20 19:24:10,344 [MainThread  ] [INFO ]  Retrieving http://export.arxiv.org/pdf/1610.08807v1 to C:\\Users\\SKAMEN~1\\AppData\\Local\\Temp/pdf-1610.08807v1.\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:19<00:47,  6.85s/it]2021-01-20 19:24:15,631 [MainThread  ] [INFO ]  Retrieving http://export.arxiv.org/pdf/2101.03330v1 to C:\\Users\\SKAMEN~1\\AppData\\Local\\Temp/pdf-2101.03330v1.\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:22<00:35,  5.89s/it]2021-01-20 19:24:18,845 [MainThread  ] [INFO ]  Retrieving http://export.arxiv.org/pdf/1705.00130v1 to C:\\Users\\SKAMEN~1\\AppData\\Local\\Temp/pdf-1705.00130v1.\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:26<00:26,  5.28s/it]2021-01-20 19:24:22,930 [MainThread  ] [INFO ]  Retrieving http://export.arxiv.org/pdf/2101.06238v1 to C:\\Users\\SKAMEN~1\\AppData\\Local\\Temp/pdf-2101.06238v1.\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:35<00:25,  6.47s/it]2021-01-20 19:24:32,045 [MainThread  ] [INFO ]  Retrieving http://export.arxiv.org/pdf/1905.05810v1 to C:\\Users\\SKAMEN~1\\AppData\\Local\\Temp/pdf-1905.05810v1.\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:43<00:20,  6.75s/it]2021-01-20 19:24:39,384 [MainThread  ] [INFO ]  Retrieving http://export.arxiv.org/pdf/cond-mat/0308016v1 to C:\\Users\\SKAMEN~1\\AppData\\Local\\Temp/pdf-cond-mat-0308016v1.\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:45<00:10,  5.40s/it]2021-01-20 19:24:41,717 [MainThread  ] [INFO ]  Retrieving http://export.arxiv.org/pdf/cond-mat/0608157v2 to C:\\Users\\SKAMEN~1\\AppData\\Local\\Temp/pdf-cond-mat-0608157v2.\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:48<00:04,  4.54s/it]2021-01-20 19:24:44,099 [MainThread  ] [INFO ]  Retrieving http://export.arxiv.org/pdf/1606.01479v1 to C:\\Users\\SKAMEN~1\\AppData\\Local\\Temp/pdf-1606.01479v1.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid electrochromic device with Tungsten oxide (WO3-x) and nafion\n",
      "  membrane: performance with varying tungsten oxide thickness\n",
      "\n",
      "Microsoft Word - Hybrid electrochromic device with Tungsten oxide- corrected   1     Hybrid electrochromic device with Tungsten oxide (WO3-x) and   nafion membrane: performance with varying tungsten oxide thickness   K Uday Kumar1, S D Bhat2,V V Giridhar2 and A Subrahmanyam1   1 Semiconductor laboratory, Department of Physics, Indian Institute of Technology Madras,   Chennai, 600036, India   2 CSIR-Central Electrochemical Research Institute-Madras Unit, CSIR Madras Complex,   Chennai 600 113, India   Abstract:   Electrochromic devices, which dynamically change color under the applied potential, are   widely studied because of its wide range of applications such as energy-efficient smart   windows, rear view mirrors and display devices etc.  In this study we are reporting four layer   electrochromic device based on tungsten oxide as a electrochromic layer and nafion   membrane as a ionic conducting layer.  Nafion membranes are generally used in fuel cell   applications because of its hi...\n",
      "\n",
      "Wall time: 58.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "arxivtext = ''\n",
    "arxivkeys = ''\n",
    "\n",
    "df_arxiv = pd.DataFrame()\n",
    "\n",
    "if arxiv_sum == True:\n",
    "    \n",
    "    try:\n",
    "        df_arxiv = parse_arxiv(query)[2] \n",
    "        df_arxiv.replace('', np.nan, inplace=True)\n",
    "        df_arxiv.dropna(inplace=True)   \n",
    "        \n",
    "        arxivtext = ''.join(list(df_arxiv['text'])) \n",
    "    \n",
    "        if compress == True:\n",
    "            arxivtext = coref_res(filter_triplet(arxivtext))\n",
    "    \n",
    "        random_num = randint(1, len(df_arxiv)) \n",
    "        \n",
    "        print(df_arxiv['page'][random_num-1]+'\\n')\n",
    "        print(df_arxiv['text'][random_num-1][:1000]+'...'+'\\n')\n",
    "    \n",
    "    except:\n",
    "        print('No data')\n",
    "     \n",
    "winsound.Beep(2500, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse Google:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T17:27:24.701679Z",
     "start_time": "2021-01-20T17:25:53.743861Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [C:\\Users\\skamenshchikov\\.wdm\\drivers\\chromedriver\\win32\\87.0.4280.88\\chromedriver.exe] found in cache\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [01:19<00:00,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Are Smart Glass Windows? | Intelligent Glass\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the Switchable Smart Glass industry, one of the questions we are asked most frequently is ‘what are Smart Windows?’, which is a broad question that has just as many answers as there are ways to ask it. Once a customer has ascertained what Smart Glass windows actually are, questions pertaining to how Smart Windows work begin to surface, however, to get any meaning out of these questions, the customer first needs to understand what a Smart Window is and how the different options involved can impact the answers. In this post, we will be looking at various types of Smart Glass Windows that Intelligent Glass offers and the differences between them in order to help you find the right product for you. For the purposes of keeping this post relevant, we will be looking at PDLC Switchable Smart Glass products and their window-based applications rather than wider definitions of ‘Smart Windows’ that may include electrochromic or photochromic glass. This post will instead focus on ‘Smart Windows’ as a term derived from Switchable Smart Glass technology. Smart Windows, Switchable Smart Glass Windows or even Switchable Windows are all broad terms used to describe a PDLC Switchable product installed in a window application. As you may appreciate, this doesn’t really narrow much down with all the Switchable product variants available and the numerous potential window applications they can be used for. Widely speaking, Switchable Glass is used in a window application for privacy requirements, as privacy is often an issue with transparent glass windows that can easily be seen through – as is the traditional point of windows. Conventionally, window privacy has been dealt with using the likes of blinds and curtains, all bringing their own set of limitations and challenges. Switchable Smart Glass on the other hand, offers a far superior solution to privacy, often being described as ‘The Future of Window Privacy’ . Smart Windows help to open up worlds of possibilities when it comes to creative interior design that can be practical, functional and stylish. With applications ranging from incredible rear projection retail window displays to ‘smart home’ innovations that transform your living space, Switchable Smart Glass windows are a versatile and effective solution to a range of needs. Smart Windows work in the same way to most Intelligent Glass products, which function by integrating a PDLC layer into the product that covers the glass surface. Unlike our competitors, this coating covers the surface edge to edge with no gap via a proprietary manufacturing process developed exclusively by Intelligent Glass. The various ways in which the PDLC coating is bonded varies from product to product depending on the level of layer protection needed, with some products encasing it inside the glass product, such as with our Switchable Smart Glass Double Glazed Units, whereas other products are manufactured by coating the layer down directly onto the glass. This layer is then wired up to a power source, which can vary from mains power to battery power depending on the requirements, allowing the product to change its state from frosted to clear on command via an activation method of the customer’s preference. When an electrical current is sent through the film, it changes from frosted to clear instantly as the crystals in the PDLC layer polarise, allowing more light to penetrate the surface as the glass changes to transparent. This is perhaps one of the more complex questions we are asked by customers, especially when they do not fully understand their own requirements in context of what is offered. The difference in cost between the potential Switchable Smart Glass options are vast, with various products to choose from that fall under the ‘Smart Window’ category, so it is of critical importance that customers work with the Intelligent Glass sales team to figure out the best option for them. Ranking as one of the least expensive products would be Switchable Smart Glass Vision Panels from Intelligent Glass. These window options are incredibly popular mainly for their effectiveness and obtainability both in terms of price and installation. Smart Glass Vision Panels make use of the space for glass window vision panels often seen on interior doors in environments such as offices, hospitals, schools and banks. Our PDLC product turns a seemingly innocuous door window panel into a privacy marvel, building the power and electrical components that operate it in the door itself, with minimal cabling and disruption. Push button operated, this small window allows the occupants to benefit from privacy without being disrupted by someone entering the room to check if it is occupied, enabling those wanting to enter to simply press the button and discreetly look into the room without interrupting the occupants. Whilst on the surface, this product is ranked as one of the least expensive Smart Glass products, there is an issue in the way of comparing it to other products. Smart Glass Vision Panels are built for a specific purpose that fulfils specific requirements, so to draw comparison with, for example, a Double Glazed Smart Glass window, could be misleading due to the differences in their functional properties. However, this could be argued as just the very reason that these products need such an assessment. Understanding not only the comparative cost of these products but also their applications, functional differences and specification strengths is an integral part of making sure you have the correct product for your project. Double Glazed Smart Glass Windows (or Smart Glass DGUs) are potentially one of the more expensive Smart Window options, with a complex manufacturing process required to produce it. The PDLC layer encased inside the unit is fully protected from outside threats such as weather, moisture or physical damage. As one of the most protected Switchable Glass window options, this product offers all the benefits of a standard DGU, such as increased insulation and UV protection, along with the benefits of Switchable Glass and truly demonstrates the risks of comparing Smart Glass products on price alone. Smart Glass windows made from double glazing offer far more benefits that are appropriate for an external window application than, for example, Toughened Switchable Glass, which, as standard, would not offer any UV protection or insulation that would likely be necessary for an external window. Whilst Toughened Switchable Glass would be the cheaper option, it would not be appropriate for this window application. Smart Glass DGUs Due to the overwhelming benefits seen with Smart Glass DGUs, the window applications it can be used for are immense, including but not limited to External Smart Glass Windows, Smart Glass Bi-Fold Doors and even Smart Glass Skylights . In fact, most external window applications can accommodate Smart Glass DGUs to their benefit as the most appropriate Smart Glass product for the application. Toughened Switchable Glass is, on the other hand, appropriate for internal window applications. This product, which consists of toughened glass with a PDLC layer bonded directly to the surface, is one of the cheaper options from Intelligent Glass, but its uses are exclusively limited to internal applications. Internal windows are indeed a common application of Switchable Smart Glass and as such, Toughened Smart Glass is by no means an unpopular product. However, even its internal uses are limited to dry environments that do not demand extra safety compliance. It also can leave the PDLC layer exposed to physical damage, which could pose a potential risk to the product. Toughened Smart Glass is a popular best-selling product, but its applications in a window application are restricted due to its limitations. One of the more innovative Smart Window applications utilises the core product of Toughened Switchable Glass; a Switchable Smart Glass Projection Screen . Often used in retail applications, Smart Windows offer an impressive way to display items and launch new products or offers in store. By keeping the items behind a Toughened Smart Glass window, retail stores have come up with ingenious ways to create a customer journey by unveiling their featured products or craft, operating the Smart Glass via timer, button, motion sensors or even voice commands. Coupled with Pro Display’s projection expertise, Intelligent Glass are able to offer these Smart Glass Windows as interactive projection screens as well, allowing the store to build an immersive and effective product display that wows. However, whilst Toughened Switchable Glass is indeed used to form the foundations of this product, there are additional complex manufacturing processes involved in creating Interactive Switchable Smart Glass Projection Screens, naturally making that particular product more expensive than standard Toughened Smart Glass. Laminate Switchable Smart Glass serves as a compromise between the ultimate protection seen from Smart Glass DGUs and the cost-effective solution of Toughened Switchable Glass, bringing different advantages and benefits. With Laminate Smart Glass, the PDLC layer is skilfully bonded and encased inside 2 sheets of laminated safety glass, helping it meet safety regulations in applications where this a concern as well as keeping it fully protected from threats such as moisture and physical damage. Cheaper than Smart Glass Double Glazing but more expensive than Toughened Smart Glass, Laminate Smart Glass is a great internal window solution for high traffic public areas or spaces that demand Health & Safety considerations, as by using safety glass, this product is compliant for such applications. Its use in wet room or shower environments also demonstrates its versatility, allowing Laminate Smart Glass to be used as internal dividing bathroom windows , partitions or even shower privacy screens, thanks to its moisture protection. The PDLC layer protection makes it extremely easy to maintain, allowing you to clean it as you would any other glass and making it perfect for applications involving children, healthcare, or any situation where a high level of cleanliness is not only important but difficult to achieve. Laminate Switchable Smart Glass also offers other advantages over Toughened Switchable Glass, specifically its sound insulating properties, which naturally aren’t as good as DGUs, but due to composition of Laminate Smart Glass, are far superior to the sound insulating properties of Toughened Smart Glass; a significant advantage for a privacy product. Switchable Laminated Glass Despite these glowing specifications, one must think very carefully about whether Laminate Smart Glass is an appropriate solution, especially should projection be a requirement, as the additional processes required to make Laminate Smart Glass projection capable are more involved than those required for Toughened Smart Glass, coming in with a higher price tag and representing the significant differences in these Smart Glass window options. Possibly the cheapest and most versatile Switchable product ironically doesn’t feature glass at all. Self-Adhesive Switchable Smart Film is a revolutionary innovative product from Intelligent Glass that allows customers to retrofit Switchable functionality to existing windows and glass. The benefits of this product are vast, from having its own built-in UV protection to its self-adhesive properties which allow for a simple install. Being significantly more affordable than many of the glass-based options, Self-Adhesive Smart Film makes Switchable windows more obtainable, allowing customers who may not wish to undergo the disruption required to fit a full glass product the opportunity to use this superior privacy solution. Just as with Toughened Smart Glass, Self-Adhesive Smart Film cannot be used in wet-room environments, however due to its retrofit install, it is appropriate for most external window applications as the product is simply being installed over the top of existing glass, which is more often than not double glazing anyway. In an application such as this, the PDLC layer is not granted the same level of protection as a full Smart Glass DGU product, as the layer has been retrofitted to the surface of the glass rather than encased inside. Despite this, the occupants will still benefit from the privacy functionality and the double glazing insulation brought by both these components individually. Self-Adhesive Switchable Smart Film In recent years, Intelligent Glass have even developed this product further to be able to offer a dual function which is especially helpful for window applications, really giving credit to the term ‘smart windows’. Self-Adhesive Switchable Smart Film not only features its own UV protection properties, but it also offers users a retrofit rear projection film as well. Operating in a similar way to Switchable Smart Glass Projection Screens, Self-Adhesive Smart Film can allow retail stores and corporate offices to convert their existing windows to rear projection Smart Windows, offering them the ability to project media content onto the window. Switching the glass to transparent to unveil the items behind it at will or via a controlled schedule helps to build tension and hype around the focus. Ideal for innovative window displays, product launches and special features, Self-Adhesive Smart Film has truly helped to revolutionise retail window displays. As this functionality is inherently built-in to the product itself, Self-Adhesive Switchable Film for projection applications costs no more than it would for privacy, making it a real contender in considerations for businesses that could make use of it. If you would like further information, a pricing quote, or to discuss ideas for using our Switchable Smart Glass and Smart Film products, please get in touch using the form below, or call us on +44 (0)1226 351 759 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "googletext = ''\n",
    "df_google = pd.DataFrame()\n",
    "\n",
    "if gogle_sum == True:\n",
    "    \n",
    "    try:\n",
    "        df_google = parse_google(query)[2]\n",
    "        df_google.replace('', np.nan, inplace=True)\n",
    "        \n",
    "        googletext = ''.join(list(df_google['text']))\n",
    "        \n",
    "        if compress == True:\n",
    "            googletext = coref_res(filter_triplet(googletext))\n",
    "            \n",
    "        random_num = randint(1,len(df_google)) \n",
    "        \n",
    "        print(list(df_google['page'])[random_num-1]+'\\n')\n",
    "        print(list(df_google['text'])[random_num-1])\n",
    "\n",
    "    except:\n",
    "        print('No data')\n",
    "    \n",
    "winsound.Beep(2500, 1000)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractive summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T17:49:54.737116Z",
     "start_time": "2021-01-20T17:49:54.712183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>link</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Smart glass or switchable glass (also smart wi...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Smart_glass</td>\n",
       "      <td>Smart_glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smart film, also called Switchable film, is a ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Smart_film</td>\n",
       "      <td>Smart_film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An electrochromic device (ECD) controls optica...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Electrochromic_d...</td>\n",
       "      <td>Electrochromic_device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Electrochromism is the phenomenon where the co...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Electrochromism</td>\n",
       "      <td>Electrochromism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smartglasses or smart glasses are wearable com...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Smartglasses</td>\n",
       "      <td>Smartglasses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Smart glass or switchable glass (also smart wi...   \n",
       "1  Smart film, also called Switchable film, is a ...   \n",
       "2  An electrochromic device (ECD) controls optica...   \n",
       "3  Electrochromism is the phenomenon where the co...   \n",
       "4  Smartglasses or smart glasses are wearable com...   \n",
       "\n",
       "                                                link                   page  \n",
       "0          https://en.wikipedia.org/wiki/Smart_glass            Smart_glass  \n",
       "1           https://en.wikipedia.org/wiki/Smart_film             Smart_film  \n",
       "2  https://en.wikipedia.org/wiki/Electrochromic_d...  Electrochromic_device  \n",
       "3      https://en.wikipedia.org/wiki/Electrochromism        Electrochromism  \n",
       "4         https://en.wikipedia.org/wiki/Smartglasses           Smartglasses  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_wiki.append(df_google).append(df_arxiv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimal compression rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T18:04:06.613575Z",
     "start_time": "2021-01-20T17:49:58.685283Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 10\n",
      "Score: 0.04 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                | 1/999 [00:28<7:59:14, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 20\n",
      "Score: 0.07 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                               | 2/999 [00:52<7:30:45, 27.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 30\n",
      "Score: 0.09 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                               | 3/999 [01:13<7:03:49, 25.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 40\n",
      "Score: 0.12 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                               | 4/999 [01:36<6:47:21, 24.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 50\n",
      "Score: 0.13 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                                                               | 5/999 [01:58<6:35:46, 23.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 60\n",
      "Score: 0.15 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                                                               | 6/999 [02:20<6:28:09, 23.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 70\n",
      "Score: 0.17 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                                                               | 7/999 [02:43<6:23:30, 23.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 80\n",
      "Score: 0.19 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                               | 8/999 [03:06<6:22:22, 23.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 90\n",
      "Score: 0.21 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                               | 9/999 [03:31<6:31:01, 23.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 100\n",
      "Score: 0.22 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                              | 10/999 [03:54<6:28:30, 23.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 110\n",
      "Score: 0.23 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                              | 11/999 [04:18<6:28:32, 23.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 120\n",
      "Score: 0.25 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                              | 12/999 [04:42<6:31:07, 23.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 130\n",
      "Score: 0.26 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█                                                                              | 13/999 [05:07<6:38:20, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 140\n",
      "Score: 0.27 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█                                                                              | 14/999 [05:31<6:35:25, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 150\n",
      "Score: 0.3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▏                                                                             | 15/999 [05:59<6:54:10, 25.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 160\n",
      "Score: 0.31 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                             | 16/999 [06:25<6:55:54, 25.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 170\n",
      "Score: 0.33 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                             | 17/999 [06:50<6:52:21, 25.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 180\n",
      "Score: 0.34 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▍                                                                             | 18/999 [07:16<6:55:36, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 190\n",
      "Score: 0.35 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▌                                                                             | 19/999 [07:47<7:25:45, 27.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 200\n",
      "Score: 0.36 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▌                                                                             | 20/999 [08:14<7:24:06, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 210\n",
      "Score: 0.39 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                             | 21/999 [08:42<7:26:58, 27.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 220\n",
      "Score: 0.4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                             | 22/999 [09:11<7:33:52, 27.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 230\n",
      "Score: 0.41 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▊                                                                             | 23/999 [09:38<7:30:26, 27.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 240\n",
      "Score: 0.42 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▉                                                                             | 24/999 [10:05<7:24:20, 27.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 250\n",
      "Score: 0.43 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▉                                                                             | 25/999 [10:31<7:18:56, 27.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 260\n",
      "Score: 0.43 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██                                                                             | 26/999 [10:58<7:16:07, 26.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 270\n",
      "Score: 0.45 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▏                                                                            | 27/999 [11:24<7:13:13, 26.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 280\n",
      "Score: 0.47 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▏                                                                            | 28/999 [11:51<7:13:37, 26.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 290\n",
      "Score: 0.48 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                            | 29/999 [12:18<7:14:16, 26.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 300\n",
      "Score: 0.49 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                            | 30/999 [12:45<7:14:57, 26.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 310\n",
      "Score: 0.49 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                            | 31/999 [13:13<7:18:33, 27.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 320\n",
      "Score: 0.5 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                            | 32/999 [13:40<7:18:44, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: 330\n",
      "Score: 0.51 \n",
      "\n",
      "Optimal volume: 330 sentences \n",
      "\n",
      "Wall time: 14min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "final_text = (wikitext + arxivtext + googletext)\n",
    "\n",
    "for i in tqdm(range(10, 10000, 10)): \n",
    "    \n",
    "    report_summary = get_summary(final_text, i)\n",
    "    scores = get_scores(report_summary, final_text)\n",
    "    \n",
    "    print('Volume:', i)\n",
    "    print('Score:', scores, '\\n')\n",
    "    \n",
    "    if scores > 0.5:\n",
    "        print('Optimal volume:', i, 'sentences', '\\n')\n",
    "        sent_number = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get extractive summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T18:09:37.392666Z",
     "start_time": "2021-01-20T18:09:28.448585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "final_text = (wikitext + arxivtext + googletext)\n",
    "report_summary = get_summary(final_text, sent_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T18:10:10.366007Z",
     "start_time": "2021-01-20T18:09:48.652146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams extracted: 0.51\n",
      "\n",
      "Compression: 0.33 \n",
      "\n",
      "Efficiency: 1.55 \n",
      "\n",
      "Smart glass or switchable glass (also smart windows or switchable windows in those applications) is a glass or glazing whose light transmission properties are altered when voltage, light, or heat is applied.==In general, the glass changes from transparent to translucent and vice versa, changing from letting light pass through to blocking some (or all) wavelengths of light and vice versa.==Smart glass technologies include electrochromic, photochromic, thermochromic, suspended-particle, micro-blind, and polymer-dispersed liquid-crystal devices.==When installed in the envelope of buildings, smart glass creates climate adaptive building shells.==Smart film, also called Switchable film, is a product that is capable of adjusting light transmission between transparent and opaque using AC power.==Due to moisture sensitivity, earlier versions of the film were used only to make smart glass by lamination on glass.==With continual improvement in moisture resistance, the new (3rd) generation of the... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "compression = round(len(word_tokenize(report_summary))/len(word_tokenize(final_text)),2) \n",
    "scores = get_scores(report_summary, final_text)\n",
    "\n",
    "print('Bigrams extracted:', str(scores))\n",
    "print('\\nCompression:', compression, '\\n')\n",
    "print('Efficiency:', str(round((scores/compression),2)), '\\n')  \n",
    "\n",
    "print((report_summary[:1000])+'...', '\\n')\n",
    "\n",
    "winsound.Beep(2500, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstractive summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paraphrase generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T18:10:21.690771Z",
     "start_time": "2021-01-20T18:10:21.677806Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if paraphrase == True:\n",
    "    \n",
    "    model_name = 'tuner007/pegasus_paraphrase'\n",
    "    torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "    \n",
    "    counter = 0\n",
    "    summ_list = []\n",
    "    \n",
    "    for i in report_summary.split('==')[:-1]:\n",
    "        summ_list.append('=='+ get_response(i,1)[0])\n",
    "    \n",
    "    summary = ' '.join(summ_list)\n",
    "\n",
    "    scores = scorer.score(summary, report_summary)\n",
    "    scores = round(100*list(list(scores.values())[0])[2])\n",
    "    report_summary = summary \n",
    "\n",
    "    print('Plagiarism:', (str(scores) + ' %'))\n",
    "\n",
    "    winsound.Beep(2500, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend the content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create keys with urls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T18:12:05.691135Z",
     "start_time": "2021-01-20T18:10:25.284721Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "ref_list = []\n",
    "pdf_list = []\n",
    "\n",
    "sent_list = list(report_summary.split(sep='=='))[:-1]\n",
    "\n",
    "for i in sent_list:\n",
    "    try:\n",
    "        df_score = df.copy()\n",
    "        df_score['score'] = df_score['text'].apply(lambda x: css(i,x))\n",
    "        df_score = df_score.sort_values(by=['score'], ascending=False)\n",
    "        \n",
    "        if str(df_score['link'].iloc[0]):\n",
    "            pdf_list.append(str(i))\n",
    "            ref_list.append(str(df_score['link'].iloc[0]))\n",
    "    except:\n",
    "        pdf_list.append('')\n",
    "\n",
    "pdf_summary = ''.join(pdf_list)\n",
    "winsound.Beep(2500, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe from tags and urls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T18:15:52.488977Z",
     "start_time": "2021-01-20T18:15:52.432129Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Smart_glass</td>\n",
       "      <td>Smart glass or switchable glass (also smart wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Smart_film</td>\n",
       "      <td>Smart film, also called Switchable film, is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Electrochromism</td>\n",
       "      <td>By doing so, an electrochromic smart window ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Smartglasses</td>\n",
       "      <td>Alternatively, smartglasses are sometimes defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://en.wikipedia.org/wiki/View,_Inc.</td>\n",
       "      <td>Founded in 2007, the company is headquartered ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            link  \\\n",
       "0      https://en.wikipedia.org/wiki/Smart_glass   \n",
       "1       https://en.wikipedia.org/wiki/Smart_film   \n",
       "2  https://en.wikipedia.org/wiki/Electrochromism   \n",
       "3     https://en.wikipedia.org/wiki/Smartglasses   \n",
       "4       https://en.wikipedia.org/wiki/View,_Inc.   \n",
       "\n",
       "                                                text  \n",
       "0  Smart glass or switchable glass (also smart wi...  \n",
       "1  Smart film, also called Switchable film, is a ...  \n",
       "2  By doing so, an electrochromic smart window ca...  \n",
       "3  Alternatively, smartglasses are sometimes defi...  \n",
       "4  Founded in 2007, the company is headquartered ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.DataFrame(list(zip(ref_list, pdf_list)), columns=['link', 'text'])\n",
    "df_merged = df_merged.sort_index(ascending=True).groupby('link', as_index=True).agg(lambda x: ' '.join(x))\n",
    "df_merged = df_merged.reindex(list(unique_everseen(ref_list))).reset_index()\n",
    "\n",
    "df_merged.replace('', np.nan, inplace=True)\n",
    "df_merged.dropna(inplace=True) \n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T18:15:56.488399Z",
     "start_time": "2021-01-20T18:15:56.477466Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "ref_list = []\n",
    "pdf_list = []\n",
    "\n",
    "trc = 0\n",
    "for i in range(len(df_merged)):\n",
    "    trc = trc + 1\n",
    "    \n",
    "    pdf_list.append(str(trc) + '. ...' + str(str(df_merged['text'].iloc[i])) + \" <u><a href=\" + str(df_merged['link'].iloc[i]) + \" target='_blank'>\" + \"More\" + \"</a></u>\" + \"<hr>\")\n",
    "    ref_list.append(str(df_merged['link'].iloc[i]))\n",
    "\n",
    "pdf_summary = ''.join(pdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:42:56.362119Z",
     "start_time": "2021-01-20T13:42:56.352148Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pdf_summary[:1000] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save docx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T18:16:02.793692Z",
     "start_time": "2021-01-20T18:15:59.667432Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "save_doc(pdf_summary, 'summary', query, scores, compression)\n",
    "winsound.Beep(2500, 3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
